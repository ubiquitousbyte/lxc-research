\chapter{Conclusion}
\label{ch:conclusion}
The results presented in the previous chapter show that the isolation overhead 
of process containerisation through resource namespacing is negligible. Disk latencies and throughput measurements 
in containers are on par with the same measurements on the host.
The networking infrastructure required to enable inter-container communication may lead to 
packet loss, higher retransmission counts and therefore increased latencies and decreased throughput.
Nevertheless, the average latency and throughput over the lifespan of a workload are almost
equivalent to running the application on the host. Furthermore, it is shown that 
hardware virtualisation mechanisms impact the resulting latencies and throughput far more 
severely \cite{https://doi.org/10.1002/cpe.5693} \cite{8457798}.
From a business perspective, the near-native performance of containers makes them highly 
favourable for consolidating multiple applications on a single server. The primary 
challenges with containers, however, lie not in performance, but rather security.

\section{Discussion}
Resource namespaces encapsulate a variety of kernel resources, but not all of them.
Namespace-unaware kernel subsystems resort to authorising operations with the user identifiers 
in the root user namespace, i.e those that were mapped by the container runtime into the container.
Containers that share these identifiers implicitly share various in-kernel data structures 
that may lead to interference. For example, the kernel used to (up to v5.13.19) impose per-user resource consumption 
restrictions such as the total number of file descriptors that can be kept open by that user, the number of 
pending signals that can be queued among all processes of that user, and the number of processes 
that the user can spawn. If one container exhausts these limits, other containers poentially owned by a different tenant are directly affected, i.e 
interfered with. This particular problem has been fixed in the v5.14 release by binding resource limit counters to user namespaces
\cite{https://patchwork.kernel.org/project/linux-hardening/cover/cover.1619094428.git.legion@kernel.org/}.
Another very important example are filesystem implementations. Filesystems associate every file 
with a unique user identifier that is its owner. Root filesystems for containers residing on the 
host are typically owned by a single user and group (allocated by the container engine) and are inaccessible by other users 
to prevent tampering. Hence, to meaningfully mount such a filesystem in multiple rootless containers, 
each container's identifier map must point to that user on the host, i.e all containers must 
share the same user identifier. This problem has been tackled by traversing the entire directory hierarchy and changing the 
ownership of each node to the root user within the container after the mount - an error-prone operation 
that can take approximately 40 seconds for a large enough root filesystem \cite{https://github.com/containerd/containerd/pull/4734}.
Not only is this operation slow, but it affects the ownership values on the host system, thereby necessitating that 
containers with different identifier mappings must have a dedicated copy of their root filesystem, which wastes storage.
This is the primary reason that rootless containers have not gained widespread adoption.
The problem was addressed in v5.12 by allowing user-space processes to associate an identifier mapping with every mount point \cite{https://lwn.net/Articles/896255/} through 
a new system call \verb|mount_setattr()|.
This identifier mapping is used to translate the caller's user identifier to the filesystem user identifier in a 
localised way \cite{https://www.kernel.org/doc/html/latest/filesystems/idmappings.html}.
In general, both examples above show that kernel developers are actively working on hardening 
the noninterference boundary and supporting container software in user-space.

\section{Future work}
This work can be further improved in two areas - the implementation of the container runtime 
and the benchmarking tool. The former is discussed first. 
The current implementation of the runtime does not incorporate the kernel's capability
framework, which allows for fine-grained control over the container's capability sets.
Another unsupported (and very important) feature
is resource control groups, also referred to as \textit{cgroups}. Resource control groups 
are a feature in the kernel that primarily deals with temporal noninterference. It is responsible 
for restricting the usage of various resources, such as processing units, memory and disk
to prevent denial of service attacks. Properly configuring control groups without degrading
application performance is a nuanced challenge that, in the 
authors opinion, is an interesting topic for a thesis.
Another innovative technology in the kernel is the eBPF subsystem, which allows 
for user-space programs to safely inject source code into arbitrary points in the kernel
and sample data. This technology can be integrated within the runtime, e.g for sampling 
behavior data of containerised processes and acting upon it, e.g if malicious intents are detected. 
The benchmark tool can also utilise eBPF for creating custom performance statistics.